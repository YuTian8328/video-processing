1
00:00:00,000 --> 00:00:10,940
So yeah, throughout the day we've had very interesting discussions about what computing is.

2
00:00:10,940 --> 00:00:19,940
And we thought that it might be nice to have some demos showing what can be done in a computational cluster.

3
00:00:19,940 --> 00:00:30,940
And these are straight out of the press, so let's see how much of a demo effect we will get.

4
00:00:30,940 --> 00:00:37,940
So, to help me today, we have [name]. Do you want to introduce yourself?

5
00:00:37,940 --> 00:00:42,940
Yeah, I'm a research software engineer at Aalto in [name]'s group.

6
00:00:42,940 --> 00:00:49,940
been there now for three years, and still having fun.

7
00:00:49,940 --> 00:00:53,940
Yeah, so it's good to hear that you're having fun.

8
00:00:53,940 --> 00:01:01,940
[name], your sound might be coming from a room microphone.

9
00:01:01,940 --> 00:01:03,940
Yeah, sorry.

10
00:01:03,940 --> 00:01:07,940
Yeah, so what do we have for you today?

11
00:01:07,940 --> 00:01:10,500
Okay, so I prepared two demos.

12
00:01:10,500 --> 00:01:13,780
So these are like two demos that might interest

13
00:01:13,780 --> 00:01:17,380
in like different people in our audience.

14
00:01:17,380 --> 00:01:20,260
So the first demo, I will demonstrate

15
00:01:20,260 --> 00:01:24,900
like how you could run this molecular dynamic simulator

16
00:01:24,900 --> 00:01:27,820
called LAMMPS, which might be physicists out there

17
00:01:27,820 --> 00:01:30,500
might be interested in, which uses like

18
00:01:30,500 --> 00:01:33,940
Mesas passing interface on MPI for parallelization.

19
00:01:33,940 --> 00:01:43,540
talk about that soonish. So, I have here a terminal. It's running on our login node. So,

20
00:01:43,540 --> 00:01:52,100
these demos are very much like demos that... Yeah. Are you going to talk about the big picture of

21
00:01:52,660 --> 00:01:57,220
what we're doing and what people should try to follow and not try to follow right now?

22
00:01:57,220 --> 00:02:05,300
Yes. So, these are very much demos that are for our site. So, they might not work for your site.

23
00:02:05,300 --> 00:02:14,420
And these demos are to show what sort of things you're capable of doing in the computing cluster.

24
00:02:14,420 --> 00:02:26,900
So, you shouldn't necessarily worry about writing these up or taking notes or anything like that.

25
00:02:26,900 --> 00:02:33,300
what we want you to focus on is the big picture of like, okay, you have a scientific problem,

26
00:02:33,300 --> 00:02:40,420
you want to solve it in the computing cluster, so what sort of workflow you might encounter.

27
00:02:42,740 --> 00:02:50,900
In this case, let's say we want to run some simulation with this LAMMPS molecular dynamics

28
00:02:50,900 --> 00:03:02,420
code. First off, I would probably want to get the example. I have prepared this git clone command.

29
00:03:03,060 --> 00:03:12,180
What this does is that it clones the LAMMPS repository, which contains the examples that

30
00:03:12,180 --> 00:03:16,660
we want to run. On the bottom, you can see history of the commands that I'm running.

31
00:03:16,660 --> 00:03:21,660
So there's like a terminal there showing what commands I'm running.

32
00:03:21,660 --> 00:03:25,660
So you might encounter this kind of like a command line interface.

33
00:03:25,660 --> 00:03:30,660
This is only one way of accessing the computational cluster.

34
00:03:30,660 --> 00:03:35,660
But we'll be working with the command line interface quite soon.

35
00:03:35,660 --> 00:03:40,660
But you can just now limit yourself to the knowledge that I'm in the computational cluster.

36
00:03:40,660 --> 00:03:42,660
I'm taking out the demos.

37
00:03:42,660 --> 00:03:53,200
And here I have now the lammps folder and I will go to examples and I will try this simple

38
00:03:53,200 --> 00:03:54,860
like intendation example.

39
00:03:54,860 --> 00:04:02,180
So in this example, we have like a 2D plane of atoms where we modify or we make an intendation

40
00:04:02,180 --> 00:04:12,060
into this atom lattice by forcing a spherical indenter

41
00:04:12,060 --> 00:04:14,620
into that lattice.

42
00:04:14,620 --> 00:04:15,420
And first of all,

43
00:04:15,420 --> 00:04:16,820
You're smashing something into it.

44
00:04:16,820 --> 00:04:20,340
Yeah, we're smashing atoms, so it sounds better.

45
00:04:20,340 --> 00:04:23,700
So I will first modify the input file a bit.

46
00:04:23,700 --> 00:04:26,100
I'll actually use nano for them.

47
00:04:26,100 --> 00:04:29,940
I will make here, I will modify one line that

48
00:04:29,940 --> 00:04:36,100
make certain that we get a dump or this kind of like output

49
00:04:36,100 --> 00:04:39,620
from the demo that we can then visualize later on.

50
00:04:39,620 --> 00:04:44,580
So we store the atom positions every 250 time steps.

51
00:04:44,580 --> 00:04:48,140
So I will modify this file.

52
00:04:48,140 --> 00:04:52,300
And what we do typically in a computed cluster,

53
00:04:52,300 --> 00:04:55,460
we'll talk about this in much more detail tomorrow.

54
00:04:55,460 --> 00:05:03,540
But what we usually do is that we write these instructions

55
00:05:03,540 --> 00:05:07,900
for the computer, what it should run on the resources,

56
00:05:07,900 --> 00:05:09,980
the computational resources.

57
00:05:09,980 --> 00:05:12,660
So what I would do here is I'm going

58
00:05:12,660 --> 00:05:17,380
to quickly write this script.

59
00:05:17,380 --> 00:05:23,900
Maybe, [name], if you want to explain shortly what I'm doing.

60
00:05:23,900 --> 00:05:29,900
Essentially, when you want to submit a photo to a cluster, you need to tell it what kind of

61
00:05:29,900 --> 00:05:34,700
resources you want. And that's what [name] is currently indicating. So in this case,

62
00:05:36,060 --> 00:05:44,620
it's using the Slurm scheduler. And the Slurm scheduler essentially reads a bash script

63
00:05:45,660 --> 00:05:50,300
and interprets these comments that are here in the beginning. Using a bash script, everything

64
00:05:50,300 --> 00:05:56,220
that's starting with a hashtag is a comment and when the scheduler sees or when the submission

65
00:05:56,860 --> 00:06:03,260
system sees this sbatch it knows that this is a command for the scheduler and here it's

66
00:06:04,220 --> 00:06:11,500
this should be running on one node it should have should get 16 cpus the memory per cpu

67
00:06:12,060 --> 00:06:18,620
should be 2 gigabytes so a total of 32 gigabytes well or 16 now yeah yeah and it should be running

68
00:06:18,620 --> 00:06:24,460
for a specific time. After that time the process would essentially be killed. So in this case it's

69
00:06:24,460 --> 00:06:33,340
10 minutes that this will be running at most. And below those comments, good explanation,

70
00:06:33,340 --> 00:06:40,460
thank you, beyond those comments we will have instructions that we expect the code to run.

71
00:06:40,460 --> 00:06:46,140
So commands that we want the code to run. So in this case we'll do this module loading. We'll

72
00:06:46,140 --> 00:06:54,860
talk about this later as well, but we will basically load some pre-installed software

73
00:06:54,860 --> 00:07:04,700
that is installed by the cluster people and we will preload that and then we will run it,

74
00:07:05,340 --> 00:07:09,580
this lmp command, with the input that we have. Let's hope that this works.

75
00:07:09,580 --> 00:07:19,100
And to quickly say, the reason why all of this software is not just available is that

76
00:07:19,100 --> 00:07:24,920
you want to keep the nodes where these tools are running as clean as possible.

77
00:07:24,920 --> 00:07:30,520
So if you would install lots and lots of software on all of the nodes, there would be a significant

78
00:07:30,520 --> 00:07:36,920
amount of resources already taken up just by that, because not necessarily every node

79
00:07:36,920 --> 00:07:43,800
has a hard drive. And if you don't have a hard drive, you need to store all of these things in

80
00:07:43,800 --> 00:07:55,000
memory. And that's why these tools are installed elsewhere. So I had a mistake in the script. So

81
00:07:55,000 --> 00:08:06,040
I fixed that. I had a wrong setting because I mistyped it. After fixing that, I submitted this

82
00:08:06,040 --> 00:08:13,560
script to the queue. In these HPC clusters, we have a queue. We'll talk more about it later.

83
00:08:13,560 --> 00:08:21,320
That will run it whenever it finds a correct place for the job to run. Currently,

84
00:08:23,160 --> 00:08:27,800
you can see that actually there's an interactive session that I have open on another

85
00:08:27,800 --> 00:08:34,640
So not a place open, but that job actually probably finished.

86
00:08:34,640 --> 00:08:37,960
So let's see.

87
00:08:37,960 --> 00:08:40,720
I just want to give one more comment here.

88
00:08:40,720 --> 00:08:44,160
I'm not sure if the Slurm command as such

89
00:08:44,160 --> 00:08:46,720
is available on clusters, because I

90
00:08:46,720 --> 00:08:52,080
think that is a script that was created in Aalto.

91
00:08:52,080 --> 00:08:56,200
So if you want to do that, or if you want to check queues,

92
00:08:56,200 --> 00:08:58,280
I think we are coming to that later as well.

93
00:08:58,280 --> 00:08:58,880
Yes.

94
00:08:58,880 --> 00:09:00,400
There was one more mistake.

95
00:09:00,400 --> 00:09:04,960
I didn't specify which MPI implementation I want to use.

96
00:09:04,960 --> 00:09:06,280
But now it's run.

97
00:09:06,280 --> 00:09:08,360
We can see the output.

98
00:09:08,360 --> 00:09:12,480
So we see what Lammps provides is this kind of like an output,

99
00:09:12,480 --> 00:09:17,200
but it also provides this dump file that, well,

100
00:09:17,200 --> 00:09:21,800
is a video basically of what happened during the run.

101
00:09:21,800 --> 00:09:25,560
There's a question in, yeah.

102
00:09:25,560 --> 00:09:28,560
If we could introduce a bit of the background of this script.

103
00:09:28,560 --> 00:09:32,640
So why do we need this script?

104
00:09:32,640 --> 00:09:36,680
Why can't we just run it, like, well,

105
00:09:36,680 --> 00:09:38,440
essentially on that command line as it is?

106
00:09:38,440 --> 00:09:40,240
Yes, that's an excellent question.

107
00:09:40,240 --> 00:09:42,680
So the question comes back to what

108
00:09:42,680 --> 00:09:47,120
we were talking earlier today about computing resources,

109
00:09:47,120 --> 00:09:49,040
because we are sharing resources.

110
00:09:49,040 --> 00:09:52,040
We are not running this on, we could run this

111
00:09:52,040 --> 00:09:54,200
on our own laptop, but in this case,

112
00:09:54,200 --> 00:09:59,440
want to run it, like, this is of course like a bit of a toy example, but if we

113
00:09:59,440 --> 00:10:04,200
would be running like an actual simulation, we would be, it would require

114
00:10:04,200 --> 00:10:08,360
a lot more resources and we, because we're sharing the resources, there needs

115
00:10:08,360 --> 00:10:10,580
to be a way of sharing these resources.

116
00:10:11,000 --> 00:10:15,380
And we'll talk about this tomorrow a lot more, how the sharing happens

117
00:10:15,440 --> 00:10:16,960
and how the queue system works.

118
00:10:17,400 --> 00:10:22,440
But basically there's like a queue system that organizes how the different jobs

119
00:10:22,440 --> 00:10:31,440
run. And I want to add to that. So normally, or in almost all clusters I've seen up until

120
00:10:31,440 --> 00:10:37,360
now, if you connect to the cluster, you are actually on the login node. So if you would

121
00:10:37,360 --> 00:10:42,360
run the login, the login node is kind of the access point for everyone to that cluster.

122
00:10:42,360 --> 00:10:48,320
So if you start running code on this directly on that node, you would run it on one machine

123
00:10:48,320 --> 00:10:50,120
that is shared by everyone.

124
00:10:50,120 --> 00:10:53,600
And very often, these machines have restrictions

125
00:10:53,600 --> 00:10:57,360
how much resources someone can actually use on them.

126
00:10:57,360 --> 00:11:02,960
And very often, they also have kind of automated script

127
00:11:02,960 --> 00:11:06,400
that kill or stops stop code that

128
00:11:06,400 --> 00:11:08,320
is taking too much resources.

129
00:11:08,320 --> 00:11:14,360
So running things on the login node is not a good idea,

130
00:11:14,360 --> 00:11:16,240
or it shouldn't be done.

131
00:11:16,240 --> 00:11:20,800
So that's why we need to write this script,

132
00:11:20,800 --> 00:11:23,280
because the script has the information on how

133
00:11:23,280 --> 00:11:25,920
for the scheduler that [name] mentioned

134
00:11:25,920 --> 00:11:29,080
on how to put it to the actual cluster.

135
00:11:29,080 --> 00:11:33,240
And the cluster is not the same here.

136
00:11:35,440 --> 00:11:36,280
Maybe.

137
00:11:37,320 --> 00:11:40,400
Yeah, I would quickly mention that you can think about it

138
00:11:40,400 --> 00:11:42,540
more if you look at the script again,

139
00:11:42,540 --> 00:11:44,840
like we asked for eight CPUs

140
00:11:44,840 --> 00:11:53,720
currently, let's say my laptop, I'm watching the stream currently. I'm having a Zoom open. I have

141
00:11:54,680 --> 00:11:59,560
some browsers open and anything. If I would run these on my own laptop, my laptop would basically

142
00:11:59,560 --> 00:12:06,840
overheat. It's currently running at about 70 degrees anyway, so it would basically be game

143
00:12:06,840 --> 00:12:11,720
over for that if I would try to run this simulation at the same time while I'm running other stuff.

144
00:12:11,720 --> 00:12:14,880
So that's why I want to run it in the cluster.

145
00:12:14,880 --> 00:12:20,840
So let's think in a more traditional high performance

146
00:12:20,840 --> 00:12:24,720
computing situation, where if you are a physicist and you

147
00:12:24,720 --> 00:12:28,000
would want to run this code, but you want to run it in a

148
00:12:28,000 --> 00:12:31,400
production size, it might be thousands of times bigger.

149
00:12:31,880 --> 00:12:37,720
So then you might need tens of nodes, hundreds of CPUs to

150
00:12:37,720 --> 00:12:39,400
actually run a big simulation.

151
00:12:39,400 --> 00:12:46,600
So in those cases, yeah, laptop isn't any more an option to do.

152
00:12:46,600 --> 00:12:50,360
But we'll talk about the parallelization later on.

153
00:12:50,360 --> 00:12:56,840
But this is like, OK, if we return back to the example,

154
00:12:56,840 --> 00:13:00,920
OK, this is all fine and nice that I managed to run it.

155
00:13:00,920 --> 00:13:05,560
But OK, if I want to now see what the result was,

156
00:13:05,560 --> 00:13:13,800
like these command line interfaces, it might be good for programming what I want the computer to

157
00:13:13,800 --> 00:13:19,960
do, what I want the queue to do, and what I want to run. But if I want to visualize it, this might

158
00:13:19,960 --> 00:13:26,120
not be the best option. So for that, at least here in Aalto, in other sites there might be

159
00:13:26,120 --> 00:13:34,200
different ones. We have this open on demand, so CSC at least has this kind of a service,

160
00:13:34,200 --> 00:13:41,320
where you can launch like a temporary virtual desktop. You might have other, like in Aalto

161
00:13:41,320 --> 00:13:47,400
there's also the VDI service, but this runs in a cluster that basically provides you a desktop

162
00:13:47,400 --> 00:13:54,200
in a browser. So you can visualize the results that you have. So let's try that out. So

163
00:13:55,400 --> 00:14:01,960
over here, I will launch one desktop with one CPU and eight gigabytes of memory. It should take

164
00:14:01,960 --> 00:14:04,760
take up like a few seconds to launch.

165
00:14:07,400 --> 00:14:09,320
While we're waiting for that,

166
00:14:09,320 --> 00:14:12,200
I want to briefly mention that essentially

167
00:14:13,600 --> 00:14:15,480
the layout of the cluster is such that

168
00:14:16,840 --> 00:14:19,580
the resources are somewhat shared.

169
00:14:22,640 --> 00:14:24,440
The login node, for example, has essentially,

170
00:14:24,440 --> 00:14:27,840
it shares the file system with the compute node.

171
00:14:27,840 --> 00:14:31,140
So anything that you create on the login node,

172
00:14:31,140 --> 00:14:37,180
the compute nodes can see, that's how essentially the data

173
00:14:37,180 --> 00:14:40,060
transfer, it's not really data transfer, it's stored at the

174
00:14:40,060 --> 00:14:42,540
same place. It's just a network file system.

175
00:14:43,660 --> 00:14:47,620
Yes. And over here, you can notice that I'm now like the

176
00:14:47,620 --> 00:14:51,860
terminal that I'm starting here is starting on some pe21. So

177
00:14:51,860 --> 00:14:55,740
it's a computing node. So it's one of the like computers that

178
00:14:55,740 --> 00:15:00,100
we have in the system. And over there, I can start Ovito, which

179
00:15:00,100 --> 00:15:12,500
this kind of like open visualization tool that is often used to simulate various simulations.

180
00:15:13,140 --> 00:15:23,940
So like this molecular dynamic simulations. So over here I will browse to the folder

181
00:15:23,940 --> 00:15:32,980
folder that the simulation was done in, so it was the indent simulation.

182
00:15:32,980 --> 00:15:37,980
And I will visualize the dump file over here.

183
00:15:37,980 --> 00:15:41,400
So you can notice that here we have the visualization.

184
00:15:41,400 --> 00:15:51,580
So it's basically like this kind of like a lattice, 2D lattice of some atoms that don't

185
00:15:51,580 --> 00:15:57,820
move and some atoms that do move and when we play the simulation we can see that we can see the

186
00:15:59,420 --> 00:16:06,460
indentation starting to happen when the push comes to solve and the lattice will move

187
00:16:07,100 --> 00:16:13,580
from the spherical indenter. So this would happen like, I don't know, like you push something into

188
00:16:13,580 --> 00:16:19,100
a metal and that would happen. So this kind of a visualization, so this is just to demonstrate

189
00:16:19,100 --> 00:16:27,260
like a workflow that you might have in a computing cluster. So you do something in the command line

190
00:16:27,260 --> 00:16:35,580
or from some other interface where you submit your job into the queue and it runs on some machine

191
00:16:36,140 --> 00:16:42,380
and once it has run you maybe use open on demand or some other way to visualize the results or

192
00:16:42,380 --> 00:16:49,660
to check the results and what is the result that you want to have.

193
00:16:57,980 --> 00:17:05,100
So this is the kind of like a workflow that you might have in the cluster.

194
00:17:05,100 --> 00:17:12,500
So yeah, so in the simulation, there's a question in the chat.

195
00:17:12,500 --> 00:17:15,780
So they say you cannot see the indenter.

196
00:17:15,780 --> 00:17:20,820
It's basically like some material

197
00:17:20,820 --> 00:17:26,020
with infinite density that pushes to the infinite force

198
00:17:26,020 --> 00:17:33,140
pushes like so that nothing cannot go over here.

199
00:17:33,140 --> 00:17:36,940
So it's some indenter that basically pushes the material

200
00:17:36,940 --> 00:17:39,500
on that side.

201
00:17:39,500 --> 00:17:41,620
OK, but this is like an example of,

202
00:17:41,620 --> 00:17:45,140
like let's say this kind of like a traditional physics

203
00:17:45,140 --> 00:17:48,660
simulation that you might do in a cluster.

204
00:17:48,660 --> 00:17:50,940
We'll talk about how do you do it in more

205
00:17:50,940 --> 00:17:54,540
detail in the coming days.

206
00:17:54,540 --> 00:17:58,380
Another example, I hope we are not running out of time

207
00:17:58,380 --> 00:18:00,500
or going too much over time.

208
00:18:00,500 --> 00:18:10,100
But another example I want to give is for the deep learning people or for the

209
00:18:11,940 --> 00:18:16,660
language processing people. In many cases, you might have a situation that

210
00:18:17,300 --> 00:18:21,860
you want to utilize, let's say, the large language models that are

211
00:18:21,860 --> 00:18:26,860
are like nowadays available everywhere basically.

212
00:18:27,540 --> 00:18:30,500
So you would want to do some,

213
00:18:30,500 --> 00:18:35,500
you want to run some queries to a large language model.

214
00:18:36,960 --> 00:18:41,960
So in this example, what I will use is like

215
00:18:42,100 --> 00:18:46,980
this already written example that we have done,

216
00:18:46,980 --> 00:18:49,900
this large language model example.

217
00:18:49,900 --> 00:18:56,060
And what the example does is that it uses this Lama2 large language model to batch

218
00:18:56,060 --> 00:18:59,420
process multiple queries to a large language model.

219
00:18:59,900 --> 00:19:07,580
So when people are doing query, like many people are using ChatGPT and programs

220
00:19:07,580 --> 00:19:10,940
like that for that, but they are closed models.

221
00:19:11,060 --> 00:19:15,300
So you cannot really know what happens behind the scenes.

222
00:19:15,300 --> 00:19:26,300
And you will just have to send a request to OpenAI and they will give you a response of what was the prompt that you queried.

223
00:19:26,300 --> 00:19:38,300
But if you're doing research into large language models or if you want to use open source alternatives for that, you might need to run it yourself.

224
00:19:38,300 --> 00:19:42,300
But those models are very heavy on the GPU requirements.

225
00:19:42,300 --> 00:19:45,300
like they are big models usually.

226
00:19:45,300 --> 00:19:49,420
So you'd need a system that has those kinds

227
00:19:49,420 --> 00:19:51,080
of resources to do it.

228
00:19:51,080 --> 00:19:55,900
And in our cluster, we have GPUs that are capable

229
00:19:55,900 --> 00:19:59,780
of running some of these large language models.

230
00:19:59,780 --> 00:20:04,780
So in this example, let's go to the batch inference folder.

231
00:20:07,300 --> 00:20:11,060
And what we have here, we have this kind

232
00:20:11,060 --> 00:20:19,940
submission script that is a bit more complicated. But what we have here is that we request

233
00:20:21,460 --> 00:20:28,500
quite a bit of memory, we request a certain number of CPUs, we request a GPU,

234
00:20:30,020 --> 00:20:37,540
and then we use like here in Aalto we have already downloaded certain deep learning models

235
00:20:37,540 --> 00:20:43,620
or pre-existing models. You could download them yourself from, let's say, HuggingFace or somewhere.

236
00:20:45,140 --> 00:20:52,980
But we have already some downloaded models existing. And over here we will use an environment

237
00:20:52,980 --> 00:21:00,580
that I have already pre-created to run this kind of like an inference script.

238
00:21:01,300 --> 00:21:05,380
And this inference script is like a Python script that loads the models and it will

239
00:21:05,380 --> 00:21:09,260
it will take some prompts that we have

240
00:21:09,260 --> 00:21:11,880
and it will run it through the model.

241
00:21:11,880 --> 00:21:14,700
So let's just run this.

242
00:21:15,800 --> 00:21:20,280
So this is the kind of like, yeah.

243
00:21:20,280 --> 00:21:22,960
You have this Python unbuffered in there.

244
00:21:22,960 --> 00:21:23,800
Yes.

245
00:21:23,800 --> 00:21:25,200
Why?

246
00:21:25,200 --> 00:21:28,000
Well, that is so that if we want to look

247
00:21:28,000 --> 00:21:30,520
at the output over here,

248
00:21:30,520 --> 00:21:36,600
it will show it to us immediately.

249
00:21:36,600 --> 00:21:39,280
That's normally not required,

250
00:21:39,280 --> 00:21:44,680
but that is just so that we can quickly see the output.

251
00:21:44,680 --> 00:21:47,840
If we would run this in a production environment,

252
00:21:47,840 --> 00:21:50,480
that wouldn't be necessary because we would be more

253
00:21:50,480 --> 00:21:54,160
interested in getting a lot of questions done.

254
00:21:54,160 --> 00:21:57,160
But over here, for the sake of the demo,

255
00:21:57,160 --> 00:22:00,600
we want to get output as soon as possible,

256
00:22:00,600 --> 00:22:03,240
so that we can see what's happening there.

257
00:22:03,240 --> 00:22:05,720
So now it's running on a GPU node.

258
00:22:05,720 --> 00:22:11,960
Our model is being loaded and the model is being initialized

259
00:22:11,960 --> 00:22:14,760
and it takes a minute to do that.

260
00:22:14,760 --> 00:22:18,880
I would also say that this Python buffer too

261
00:22:18,880 --> 00:22:22,880
is pretty important if you need to debug.

262
00:22:22,880 --> 00:22:23,720
Yes.

263
00:22:23,720 --> 00:22:25,680
Because if you have some statements,

264
00:22:25,680 --> 00:22:29,120
some print statements in and don't have that,

265
00:22:29,120 --> 00:22:33,880
or tail the print statements to directly write out,

266
00:22:33,880 --> 00:22:39,760
you can easily end up with code that you think is running,

267
00:22:39,760 --> 00:22:44,560
or think is not running anymore, but actually ran.

268
00:22:44,560 --> 00:22:47,640
Yeah. So the model run,

269
00:22:47,640 --> 00:22:48,920
it produced the output,

270
00:22:48,920 --> 00:22:51,600
but the output is pretty hard to read from this.

271
00:22:51,600 --> 00:22:59,440
so it also produced the output into like a response file so in order to visualize a bit

272
00:22:59,440 --> 00:23:11,040
better I'm loading this JSON formatter called jq and running this command to open it up in

273
00:23:11,040 --> 00:23:17,360
the editor so we can see what sort of responses it gave. So for example what is the history of

274
00:23:17,360 --> 00:23:22,360
of the Eiffel Tower and then it describes in lots of detail

275
00:23:22,600 --> 00:23:24,760
the history of the Eiffel Tower.

276
00:23:24,760 --> 00:23:28,240
And these kinds of like batch processing is very important

277
00:23:28,240 --> 00:23:32,800
when in our case, we had,

278
00:23:32,800 --> 00:23:35,200
I'm not certain how many prompts we have here,

279
00:23:35,200 --> 00:23:37,640
maybe a hundred, maybe a few hundred,

280
00:23:37,640 --> 00:23:42,640
but like if we want to test out these AI models

281
00:23:43,280 --> 00:23:46,600
with thousands and thousands of different prompts,

282
00:23:46,600 --> 00:23:52,280
It could get pretty expensive if you want to use, let's say, OpenAI's models.

283
00:23:52,520 --> 00:23:59,960
Or maybe you want to test out how different models behave, what sort of output they produce.

284
00:24:00,040 --> 00:24:01,800
Or maybe you want to try different things.

285
00:24:01,840 --> 00:24:13,880
For these, it might be a lot cheaper and a lot easier to do this kind of batch processing in the compute cluster compared to, let's say, using an already existing ChatGPT.

286
00:24:13,880 --> 00:24:18,880
But those are also good ways of doing a research, of course.

287
00:24:18,880 --> 00:24:20,880
This is only one way of doing research.

288
00:24:20,880 --> 00:24:29,880
But if you need to process a huge bunch of these queries, yes, this is one way of doing that.

289
00:24:29,880 --> 00:24:36,360
So but these kind of stuff you will be able or hopefully you will be able to do

290
00:24:37,000 --> 00:24:43,480
after this course or you will know how you should get started on working these kinds of examples.

291
00:24:49,800 --> 00:24:56,040
But we like there are many questions already in the in the chat about like many of the concepts

292
00:24:56,040 --> 00:25:03,000
we introduced here. And don't worry, like we'll go through the concepts in like better detail

293
00:25:03,000 --> 00:25:12,040
or in more detail like during the next upcoming two days. We won't like go through them in this

294
00:25:12,040 --> 00:25:17,080
one half an hour session and expect that you would need to like learn everything from this.

295
00:25:17,080 --> 00:25:23,720
This was just a demo. This is just the preview to know what kind of things you might learn.

296
00:25:26,040 --> 00:25:29,440
And really to show the point that what we're learning

297
00:25:29,440 --> 00:25:32,460
the next few days, we're not doing something ourselves,

298
00:25:32,460 --> 00:25:35,000
but we're telling a computer how to do it.

299
00:25:35,000 --> 00:25:38,200
And thus we can tell the computer to do it 10 times

300
00:25:38,200 --> 00:25:40,380
or a hundred times for us automatically.

301
00:25:42,480 --> 00:25:43,320
Okay.

302
00:25:45,000 --> 00:25:46,840
With that being said, it's a break time.

303
00:25:46,840 --> 00:25:51,420
So after the break, we begin,

304
00:25:51,420 --> 00:25:54,440
we do a practice connecting to the cluster.

305
00:25:56,040 --> 00:25:58,040
Let's see you then.

306
00:26:00,040 --> 00:26:01,040
Bye.

307
00:26:02,040 --> 00:26:03,040
Bye.

308
00:26:03,040 --> 00:26:04,000
Bye.

