- workshop_title: Tuesday tools and techniques for HPC
- workshop_description: >
    Do you use supercomputers in your research work? Are you curious
    about making your computing faster and more efficient? Join us for
    TTT4HPC: four self-contained episodes on best practices in High
    Performance Computing. This is a great chance to enhance your
    computational skills. What you will learn is also used a lot
    outside academia whenever large scale computations are needed.

    Improve your cluster workflows! You've had a basic course on
    working with a cluster - but what do people actually do? This
    course shows practical examples and tips which may help you, but
    aren't usually covered in either basic or advanced courses.

    We won't go so deep into each topic that you know everything about
    it, but you learn what is possible, see some examples, and know
    where to follow up on the tools that are right for you. The format
    is designed to be "fireside chat with experts", a combination of
    demos, type-along, and independent exercises. You can engage at
    different levels, depending on your interest.

    Links:

    - Playlist: https://www.youtube.com/playlist?list=PLpLblYHCzJABy4epFn-rqsfDbUZ1ff5Pl

    - Workshop webpage: https://scicomp.aalto.fi/training/scip/ttt4hpc-2024/

    - CodeRefinery: https://coderefinery.org

- input: raw/day1-obs.mkv

- output: out/day1.1-icebreaker.mkv
  title: 1.1 Icebreaker
  description: >-
    The icebreaker/intro session of the day  You probably don't want
    to watch this and instead will go to the main material, unless you
    want the full "fireside chat" experience.

  editlist:
    - start: 00:15:20
    - end: 00:24:26

- output: out/day1-intro.mkv
  title: 1.2 Intro
  description: >-
    The practical information of the day.  You probably want to skip
    this unless you want a full simulation of the course.

  editlist:
    - start: 00:24:26
    - end: 00:30:18

- output: out/day1-resources.mkv
  title: 1.3 Resources
  description: >-
    How do you know how many resources to request on the cluster?
    This is a good question, but the answer usually isn't obvious (and
    is usually hand-waved at the start).  The answer is somehow
    "measure and test" - and that's what you will learn how to do
    here.

    Learning goals:

    - We understand what the Slurm job scheduler tries to do.

    - We understand the dimensions of a Slurm job and how to specify them.

    - Understand that job parameters affect not only resource use but also how long it will queue.

    - Get a visual understanding of what the Slurm job scheduler does.

    - Being able to reduce the system size to a small enough size to be able to test the scaling of a code.

    - Timing a series of runs with increasing number of cores.

    - How to measure and choose the right amount of memory

    - Reading files is a common bottleneck

    - One large file is usually faster than many small files

    - Local hard disks and ramdisks can be much faster


    Materials:

    1. https://coderefinery.github.io/TTT4HPC_resource_management/scheduling/

    2. https://coderefinery.github.io/TTT4HPC_resource_management/num-cores/

    3. https://coderefinery.github.io/TTT4HPC_resource_management/memory/

  editlist:
    - start: 00:30:18
    - 00:34:28: 1. Job scheduling and Slurm basics
    - 00:55:56: 2. How to choose the number of cores
    - 01:10:15: 3. Choosing the right amount of memory
    - end: 01:24:59

- output: out/day1-io.mkv
  title: 1.4 I/O
  description: >-
    In this lesson we discuss common I/O problems, diagnosing them and
    avoiding them. I/O issues are usually about how the workflow is
    structured and can be fixed or alleviated by restucturing, moving
    the reads and writes to move convenient times or using the right
    storage system.

    This lesson is mostly a demonstration, with some general
    discussion. We recommend you follow the demonstration.

    Main points:
    - Filesystem can be the slowest part of many jobs
    - Networked filesystems tend to be best at large files, bad at many small

    https://coderefinery.github.io/TTT4HPC_resource_management/io-best-practices/

  editlist:
    - start: 01:38:48
    - -: I/O best practices
    - 02:22:59: News for the day
    - end: 02:24:32


- input: raw/day2-obs.mkv

- output: out/day2-interactive.mkv
  title: 2.1 Day to day cluster work
  description: >-

    Today, we look at ways of working on the cluster, with a focus on
    interactive working.  We go over project arrangement, moving data
    around (one way transfer and two-way syncing), planning for these
    transfers, code syncing with git, graphical interfaces, working
    interactively (interactive jobs, screen/tmux), and VS Code for HPC.

    https://coderefinery.github.io/TTT4HPC_Interactive/

  editlist:
    - start: 00:19:42
    - -: Introduction
    - 00:24:45: § Motivation
    - 00:30:58: § Project arrangement
    - 00:48:48: "§ Data sync: moving data around"
    - 00:53:06: "Data sync: rsync (one-way)"
    - 01:03:15: "Data sync: unison (two-way)"
    - 01:10:28: "Data sync: git-annex"
    - 01:14:23: "Data sync: sshfs (remote mount via ssh)"
    - stop: 01:19:32
    - start: 01:29:11
    - -: § Code sync
    - 01:34:23: § Graphical interfaces
    - 01:34:44: "Graphical interfaces: X forwarding"
    - 01:41:10: "Graphical interfaces: Open OnDemand"
    - 01:42:31: § Working interactively
    - 01:43:11: "Working interactively: Interactive jobs"
    - 01:49:24: "Working interactively: screen/tmux"
    - 01:55:52: § VS Code on HPC
    - 01:58:41: "VS Code: Remote-SSH"
    - cover: {begin: 02:03:24, end: 02:03:27, w: 840, h: 540}
    - 02:04:20: "VS Code: transferring files"
    - 02:06:52: "VS Code: shell and Slurm"
    - 02:10:20: "VS Code: debugging (debugpy)"
    - 02:18:31: Wrap up, what is next week
    - end: 02:20:22


- input: raw/day3-obs.mkv

- output: out/day3-containers.mkv
  title: 3.1 Containers on HPC clusters
  description: >-
    Containers are a way to run applications in a self-contained
    environment with all the tools that the specific application
    needs.  They are very useful for scientific software, which may
    have difficult dependencies and need to run on a variety of systems
    with widely varying specifications.

    Unlike most container tutorials you can find, this focuses on HPC
    and scientific computing use cases, using Apptainer
    (=Singularity).  We go over both the theory behind containers and
    the most common operations: pulling, building yourself, running,
    and bind-mounting.

    Material: https://coderefinery.github.io/ttt4hpc_containers/

  editlist:
    - start: 00:22:17
    - -: § Intro to containers
    - -: What is a container?
    - 00:36:47: What is the intended use case of Apptainer?
    - 00:42:46: Apptainer vs Singularity
    - 00:43:38: § Basics of running containers
    - 01:00:39: § Intro to container images
    - stop: 01:19:02
    - start: 01:28:51
    - -: "Q&A after the break"
    - 01:31:13: § Building Apptainer images
    - 01:31:17: Pulling images (from a Docker registry)
    - 01:37:24: Creating an image using a specification file (.sif)
    - 01:45:30: Running additional installation commands during image creation
    - 01:52:06: Setting environment variables in the image
    - 01:56:57: Adding documentation to your image
    - 01:58:28: Examining the container
    - 02:00:11: Summary of the section
    - 02:00:56: § Binding folders into your container
    - 02:14:02: "§ Wrap-up, Q&A, preparation for next week"
    - stop: 02:18:51
